---
title: Hands-on training session 1
subtitle: Introduction, revision and running basic models
date: "`r Sys.Date()`"
fontsize: 12pt
author:
  - Matt Denwood
  - Giles Innocent
theme: metropolis
aspectratio: 43
colortheme: seahorse
header-includes: 
  - \input{preamble}
fig_caption: true
classoption: compress, c
output:
    beamer_presentation:
        pandoc_args: ["-t", "beamer"]
        slide_level: 2
    html_document: default
---

```{r rendering, eval=FALSE, include=FALSE}
# To render this as both html and PDF (beamer) slides run:
rmarkdown::render('Adv1_Theory.Rmd', 'all')
# Or just for html:
rmarkdown::render('Adv1_Theory.Rmd', 'html_document')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Course Outline and Practicalities

## Overview

Date/time:

  - 19th February 2020
  - 14.00 - 15.30

Teachers:

  - Matt Denwood (presenter)
  - Giles Innocent

## Accessing the teaching material

Demonstration of GitHub and where the files are...

## Preparation

- Do we all have R and JAGS installed?

- Have we all looked at the preparation material?



# Session 1a:  Theory and application of MCMC

## Bayes Rule

Bayes' theorem is at the heart of Bayesian statistics.  This states that:

$P(\theta|Y) = \frac{P(\theta)\times P(Y|\theta)}{P(Y)}$
Where:
$\theta$ is our parameter value(s);
$Y$ is the data that we have observed;
$P(\theta|Y)$ is the posterior probability of the parameter value(s) given the data and priors;
$P(\theta)$ is the prior probability of the parameters BEFORE we had observed the data;
$P(Y|\theta)$ is the likelihood of the data given the parameters value(s), as discussed above; and
$P(Y)$ is the probability of the data, integrated over all parameter space.

---

Note that $P(Y)$ is rarely calculable except in the simplest of cases, but is a constant for a given model.  So in practice we usually work with the following:

$P(\theta|Y) \propto P(\theta)\times P(Y|\theta)$

Our Bayesian posterior is therefore always a combination of the likelihood of the data, and the parameter priors

But for more complex models the distinction between what is 'data' and 'parameters' can get blurred!

## MCMC (revision)

TODO

- Brief highlight of important points re convergence and effective sample size

## Exercise

TODO

Using the same function to estimate prevalence for different priors and datas

Including positives = 0

Care with convergence and sample size

## Solution

TODO

# Session 1b:  Working with basic models (apparent prevalence)

## MCMC software

We have seen that we can write a Metropolis algorithm but this is complex and inefficient

There are a number of general purpose langauages that allow us to define the problem in a faily intuitive manner and leave the details to the software. Among the latter are BUGS (Bayesian inference Using Gibbs Sampling) JAGS (Just another Gibbs Sampler) and STAN (named in honour of Stanislaw Ulam, pioneer of the Monte Carlo method).

## JAGS

JAGS is a declarative (non-procedural) programming language. That is the order of statements does not matter. When implemented the interpreted just considers the appropriate line of code to interpret in terms of likelihood and prior. That is why you can only define each variable (LHS) once.

---

A simple JAGS model might look like this:

```{r eval=FALSE}
model{
  # Likelihood part:
  Positives ~ dbinom(prevalence, TotalTests)
  
  # Prior part:
  prevalence ~ dbeta(2, 2)
  
  # Hooks for automatic integration with R:
  #data# Positives, TotalTests
  #monitor# prevalence
  #inits# prevalence
}
```

```{r include=FALSE}
model_definition <- "
model{
  # Likelihood part:
  Positives ~ dbinom(prevalence, TotalTests)
  
  # Prior part:
  prevalence ~ dbeta(2, 2)
  
  # Hooks for automatic integration with R:
  #data# Positives, TotalTests
  #monitor# prevalence
  #inits# prevalence
}
"
```

---

There are two model statements:

```{r eval=FALSE}
Positives ~ dbinom(prevalence, TotalTests)
```

states that the number of $Positive$ test samples is Binomially distributed with probability parameter $prevalence$ and total trials $TotalTests$

```{r eval=FALSE}
prevalence ~ dbeta(2,2)
```

states that our prior probability distribution for the parameter $prevalence$ is Beta(2,2)

These are very similar to the likelihood and prior functions defined in the preparatory exercise

---

The other lines in this model are automated hooks to allow the runjags package to make sure that the correct R objects are passed to R as data, and that we get samples for the parameter we want to monitor. These statements are ignored by JAGS.

One of the advantages of using something like JAGS or STANis that much of the detail of the coding is shielded from us which means that the code is accessible to a wider variety of audiences. Running this model is much easier (and more efficient) than the Metropolis algorithm code.

---

To run this model, copy/paste the code above into a new text file called "basicjags.bug" in the same folder as your current working directory.

```{r include=FALSE}
cat(model_definition, file='basicjags.bug')
```

Then run:

```{r}
library('runjags')

# data to be retrieved by runjags:
Positives <- 7
TotalTests <- 10

# initial values to be retrieved by runjags:
prevalence <- list(chain1=0.05, chain2=0.95)
```

---

```{r}
results <- run.jags('basicjags.bug', n.chains=2)
```

You should see some updates then it will be finished

```{r include=FALSE}
unlink('basicjags.bug')
runjags.options(silent.jags=TRUE)
```

---

First check for convergence based on trace plots:

```{r eval=FALSE, include=TRUE}
plot(results)
```

```{r include=FALSE}
pt <- plot(results)
```

---

```{r echo=FALSE}
print(pt[[1]])
```

---

```{r echo=FALSE}
print(pt[[2]])
```

---

```{r echo=FALSE}
print(pt[[3]])
```

---

```{r echo=FALSE}
print(pt[[4]])
```

---

Then check the effective sample size (SSeff) and Gelman-Rubin statistic (psrf):

```{r}
results
```

If these both look OK (psrf < 1.05 and SSeff > 1000) then you can use the posterior summary statistics.



## Exercise

TODO

Run this model for yourselves

Adjust data and priors


## Solution

TODO

# Session 1c:  Basics of latent-class models (imperfect test)

## Imperfect tests

TODO

Usually, however, we do not have a perfect test to know how many are truly positive (negative).
Say we have a test with known sensitiveity of 0.8, and known specificity of 0.95. We know therefore that:
$Prev_{obs} = (Prev_{true}\times Se) + ((1-Prev_{true})\times (1-Sp))$
$\implies Prev_{true} = \frac{Prev_{obs}-(1-Sp)}{Se-(1-Sp)}$


## Model specification

How to write the model in JAGS, and specify priors for Se and Sp

## Priors

Where to get priors in real life

PriorGen pacakge

## Exercise

Run the same model in runjags with imperfect Se/Sp with priors we give them based on mean and 95% CI

Compare results

