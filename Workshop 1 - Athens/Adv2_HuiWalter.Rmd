---
title: Hands-on training session 2
subtitle: Hui-Walter models for diagnostic test evaluation
date: "`r Sys.Date()`"
author:
  - Matt Denwood
  - Giles Innocent
theme: metropolis
aspectratio: 43
colortheme: seahorse
header-includes: 
  - \input{preamble}
params:
  presentation: TRUE
output:
  beamer_presentation:
      pandoc_args: ["-t", "beamer"]
      slide_level: 2
  html_document: default
---

```{r rendering, eval=FALSE, include=FALSE}
# To render this as PDF (beamer) slides run:
rmarkdown::render('Adv2_HuiWalter.Rmd', 'beamer_presentation', params=list(presentation=TRUE))
# And for html:
rmarkdown::render('Adv2_HuiWalter.Rmd', 'html_document', params=list(presentation=FALSE))
```

```{r setup, include=FALSE}
# Reduce the width of R code output for PDF only:
if(params$presentation) options(width=60)
knitr::opts_chunk$set(echo = TRUE)

library('runjags')
runjags.options(silent.jags=TRUE)
```

# Introduction

## Overview

Date/time:

  - 19th February 2020
  - 16.00 - 17.00

Teachers:

  - Matt Denwood (presenter)
  - Giles Innocent

## Recap

Important points from session 1

TODO


# Session 2a:  Hui-Walter models for 2 tests and 1 population

## Hui-Walter Model

Background (not necessarily Bayesian)

Rabbits and hats

## Model Specification


```{r include=FALSE}
hw_definition <- "model{
  Tally ~ dmulti(prob, TotalTests)
  
  # Test1- Test2-
	prob[1] <- (prev * ((1-se[1])*(1-se[2]))) + ((1-prev) * ((sp[1])*(sp[2])))

  # Test1+ Test2-
	prob[2] <- (prev * ((se[1])*(1-se[2]))) + ((1-prev) * ((1-sp[1])*(sp[2])))

  # Test1- Test2+
	prob[3] <- (prev * ((1-se[1])*(se[2]))) + ((1-prev) * ((sp[1])*(1-sp[2])))

  # Test1+ Test2+
	prob[4] <- (prev * ((se[1])*(se[2]))) + ((1-prev) * ((1-sp[1])*(1-sp[2])))
 
  prev ~ dbeta(1, 1)
  se[1] ~ dbeta(1, 1)
  sp[1] ~ dbeta(1, 1)
  se[2] ~ dbeta(1, 1)
  sp[2] ~ dbeta(1, 1)

  #data# Tally, TotalTests
  #monitor# prev, prob, se, sp
  #inits# prev, se, sp
}
"
cat(hw_definition, file='basic_hw.bug')
```

```{r comment='', echo=FALSE}
cat(hw_definition, sep='\n')
```

---

- And run it:

```{r}
twoXtwo <- matrix(c(48, 12, 4, 36), ncol=2, nrow=2)
twoXtwo

library('runjags')

Tally <- as.numeric(twoXtwo)
TotalTests <- sum(Tally)

prev <- list(chain1=0.05, chain2=0.95)
se <- list(chain1=c(0.5,0.99), chain2=c(0.99,0.5))
sp <- list(chain1=c(0.5,0.99), chain2=c(0.99,0.5))

results <- run.jags('basic_hw.bug', n.chains=2)
```

[Remember to check convergence and effective sample size!]

---

```{r}
results
```

---

```{r echo=FALSE}
res <- summary(results)[,c(1:3,9,11)]
res[] <- round(res, 3)
knitr::kable(res)
```

- Note wide confidence intervals


## Practicalities

Care with order of combinations in dmultinom

Lots of data needed

  * And/or strong priors for one of the tests

Convergence can be tricky


## Label Switching

How to interpret a test with Se=0% and Sp=0%?

...

The test is perfect - we are just holding it upside down...

...

We can force se+sp >= 1:

```{r eval=FALSE}
  se[1] ~ dbeta(1, 1)
  sp[1] ~ dbeta(1, 1)T(1-se[1], )
```

...

Or:

```{r eval=FALSE}
  se[1] ~ dbeta(1, 1)T(1-sp[1], )
  sp[1] ~ dbeta(1, 1)
```

But not both!

This allows the test to be useless, but not worse than useless


## Simulating data

Analysing simulated data is useful to check that we can recover parameter values.

Some simultion code:

```{r}
se1 <- 0.9
sp1 <- 0.95
sp2 <- 0.99
se2 <- 0.8
prevalence <- 0.5
N <- 100

truestatus <- rbinom(N, 1, prevalence)
Test1 <- rbinom(N, 1, (truestatus * se1) + ((1-truestatus) * (1-sp1)))
Test2 <- rbinom(N, 1, (truestatus * se2) + ((1-truestatus) * (1-sp2)))

twoXtwo <- table(Test1, Test2)
twoXtwo
Tally <- as.numeric(twoXtwo)
```


## Exercise

Modify JAGS code to force tests to be better than useless

Simulate data and recover parameters for:

  * N=10, N=100, N=1000


## Optional Exercise

Use priors for test1 taken from session 1 and compare the results


## Solution

Model definition:

```{r include=FALSE}
hw_definition <- "model{
  Tally ~ dmulti(prob, TotalTests)
  
  # Test1- Test2-
	prob[1] <- (prev * ((1-se[1])*(1-se[2]))) + ((1-prev) * ((sp[1])*(sp[2])))

  # Test1+ Test2-
	prob[2] <- (prev * ((se[1])*(1-se[2]))) + ((1-prev) * ((1-sp[1])*(sp[2])))

  # Test1- Test2+
	prob[3] <- (prev * ((1-se[1])*(se[2]))) + ((1-prev) * ((sp[1])*(1-sp[2])))

  # Test1+ Test2+
	prob[4] <- (prev * ((se[1])*(se[2]))) + ((1-prev) * ((1-sp[1])*(1-sp[2])))
 
  prev ~ dbeta(1, 1)
  se[1] ~ dbeta(HPSe[1,1], HPSe[1,2])T(1-sp[1], )
  sp[1] ~ dbeta(HPSp[1,1], HPSp[1,2])
  se[2] ~ dbeta(HPSe[2,1], HPSe[2,2])T(1-sp[2], )
  sp[2] ~ dbeta(HPSp[2,1], HPSp[2,2])

  #data# Tally, TotalTests, HPSe, HPSp
  #monitor# prev, prob, se, sp
  #inits# prev, se, sp
}
"
cat(hw_definition, file='basic_hw.bug')
```

```{r comment='', echo=FALSE}
cat(hw_definition, sep='\n')
```

Note that we specify the prior hyperparameters as data so we can change these from R without havÃ­ng to edit the model file (this is optional!)

```{r}
se1 <- 0.9
sp1 <- 0.95
sp2 <- 0.99
se2 <- 0.8
prevalence <- 0.5

N <- 100

truestatus <- rbinom(N, 1, prevalence)
Test1 <- rbinom(N, 1, (truestatus * se1) + ((1-truestatus) * (1-sp1)))
Test2 <- rbinom(N, 1, (truestatus * se2) + ((1-truestatus) * (1-sp2)))

twoXtwo <- table(Test1, Test2)
twoXtwo

library('runjags')

Tally <- as.numeric(twoXtwo)
TotalTests <- sum(Tally)
HPSe <- matrix(c(1,1,1,1), nrow=2, ncol=2)
HPSp <- matrix(c(1,1,1,1), nrow=2, ncol=2)

prev <- list(chain1=0.05, chain2=0.95)
se <- list(chain1=c(0.5,0.99), chain2=c(0.99,0.5))
sp <- list(chain1=c(0.5,0.99), chain2=c(0.99,0.5))

results <- run.jags('basic_hw.bug', n.chains=2)
results
```


## Optional Solution

```{r}
HPSe[1,] <- c(148.43, 16.49)
HPSp[1,] <- c(240.03, 12.63)

HPSe
HPSp

results <- run.jags('basic_hw.bug', n.chains=2)
results
```


# Session 2b:  Hui-Walter models for 2 tests and N populations

## Independent intercepts for populations

```{r eval=FALSE}
model{
  for(p in 1:Populations){
    Tally[1:4, p] ~ dmulti(prob[1:4, p], TotalTests[p])
  
    # Test1- Test2- Pop1
	  prob[1, p] <- (prev[p] * ((1-se[1])*(1-se[2]))) + ((1-prev[p]) * ((sp[1])*(sp[2])))

    ## etc ##

    prev[p] ~ dbeta(1, 1)
  }

  se[1] ~ dbeta(HPSe[1,1], HPSe[1,2])T(1-sp[1], )
  sp[1] ~ dbeta(HPSp[1,1], HPSp[1,2])
  se[2] ~ dbeta(HPSe[2,1], HPSe[2,2])T(1-sp[2], )
  sp[2] ~ dbeta(HPSp[2,1], HPSp[2,2])

  #data# Tally, TotalTests, Populations, HPSe, HPSp
  #monitor# prev, prob, se, sp
  #inits# prev, se, sp
}
```

...

Data and initial values start to get complicated...


## Auto Hui-Walter

We would usually start with individual-level data in a dataframe e.g.:

```{r}
se1 <- 0.9
sp1 <- 0.95
sp2 <- 0.99
se2 <- 0.8
prevalences <- c(0.1, 0.5, 0.9)
N <- 100

simdata <- data.frame(Population = sample(seq_along(prevalences), N, replace=TRUE))
simdata$probability <- prevalences[simdata$Population]
simdata$truestatus <- rbinom(N, 1, simdata$probability)
simdata$Test1 <- rbinom(N, 1, (simdata$truestatus * se1) + ((1-simdata$truestatus) * (1-sp1)))
simdata$Test2 <- rbinom(N, 1, (simdata$truestatus * se2) + ((1-simdata$truestatus) * (1-sp2)))
  
head(simdata)
```

[Except that probability and truestatus would not normally be known!]

---

The model code and data format for an arbitrary number of populations (and tests) can be determined automatically

There is a function (soon to be included in the runjags package, but for now provided in the GitHub repo) that can do this for us:

```{r}
simdata$Population <- factor(simdata$Population, levels=seq_along(prevalences), labels=paste0('Pop_', seq_along(prevalences)))

source("autohuiwalter.R")
auto_huiwalter(simdata[,c('Population','Test1','Test2')], outfile='autohw.bug')
```

---

This generates self-contained model/data/initial values etc (ignore covse and covsp for now):

```{r echo=FALSE}
cat(readLines('autohw.bug'), sep='\n')
```

---

And can be run directly from R:

```{r}
results <- run.jags('autohw.bug')
```

---
```{r}
results
```


## Observation-level model specification

```{r include=FALSE}
glmhw_definition <- "model{

  for(i in 1:N){
    Status[i] ~ dcat(prob[i, ])
  
	  prob[i,1] <- (prev[i] * ((1-se[1])*(1-se[2]))) + 
	              ((1-prev[i]) * ((sp[1])*(sp[2])))
	  prob[i,2] <- (prev[i] * ((se[1])*(1-se[2]))) + 
	              ((1-prev[i]) * ((1-sp[1])*(sp[2])))
	  prob[i,3] <- (prev[i] * ((1-se[1])*(se[2]))) + 
	              ((1-prev[i]) * ((sp[1])*(1-sp[2])))
	  prob[i,4] <- (prev[i] * ((se[1])*(se[2]))) + 
	              ((1-prev[i]) * ((1-sp[1])*(1-sp[2])))
	  
	  logit(prev[i]) <- intercept + population_effect[Population[i]]
  }

  intercept ~ dnorm(0, 0.33)
  population_effect[1] <- 0
  for(p in 2:Pops){
    population_effect[p] ~ dnorm(0, 0.1)
  }
  se[1] ~ dbeta(1, 1)T(1-sp[1], )
  sp[1] ~ dbeta(1, 1)
  se[2] ~ dbeta(1, 1)T(1-sp[2], )
  sp[2] ~ dbeta(1, 1)

  #data# Status, N, Population, Pops
  #monitor# intercept, population_effect, se, sp
  #inits# intercept, population_effect, se, sp
}
"
cat(glmhw_definition, file='glm_hw.bug')
```


```{r comment='', echo=FALSE}
cat(glmhw_definition, sep='\n')
```

---

Just like in session 1, the main difference is the prior for prevalence (this time in each population)

We also need to give initial values for intercept and population_effect rather than prev, and tell run.jags the data frame from which to extract the data (except N and Pops):

```{r}
intercept <- list(chain1=-1, chain2=1)
population_effect <- list(chain1=c(NA, 1, -1), chain2=c(NA, -1, 1))
se <- list(chain1=c(0.5,0.99), chain2=c(0.99,0.5))
sp <- list(chain1=c(0.5,0.99), chain2=c(0.99,0.5))

simdata$Status <- with(simdata, factor(interaction(Test1, Test2), levels=c('0.0','1.0','0.1','1.1')))
N <- nrow(simdata)
Pops <- length(levels(simdata$Population))
glm_results <- run.jags('glm_hw.bug', n.chains=2, data=simdata)
```

---

Also like in session 1, the estimates for se/sp should be similar, although this model runs more slowly.

```{r echo=FALSE}
if(!params$presentation){
  cat('Results from the HW model:\n\n\n')
  results
}
```

```{r echo=FALSE}
if(!params$presentation){
  cat('Results from the GLM model:\n\n\n')
  glm_results
}
```

Note:  this model could be used as the basis for adding covariates

For a handy way to generate a GLM model see runjags::template.jags

  * Look out for integration with autohuiwalter in the near (ish) future...

## Practicalities

Need to be very careful with tabulating the data, or use automatically generated code

Works best when populations have very different prevalences


## Exercise

Play around with the autohuiwalter function

Notice the model and data and initial values are in a self contained file

Ignore the covse and covsp for now

